{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Rajinder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Rajinder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rajinder\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Downloading and importing necessary libraries and modules\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP is  an important  deception is data analytics and those who have \n",
      "strong skill sets in NLP have a great chance to get a job in data analytics \n",
      "The following video covers some important topics in NLP Please watch that \n",
      "to the end and answer the following questions You should also leave comment \n",
      "for 2 peer learners\n"
     ]
    }
   ],
   "source": [
    "\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "\n",
    "text = \"\"\"NLP is ? an important ! deception is data analytics and those who have \n",
    "strong skill sets in NLP have a great chance to get a job in data analytics. \n",
    "The following video covers some important topics in NLP. Please watch that \n",
    "to the end and answer the following questions. You should also leave comment \n",
    "for 2 peer learners:\"\"\"\n",
    "\n",
    "no_punction = \"\"\n",
    "for char in text:\n",
    "   if char not in punctuations:\n",
    "       no_punction = no_punction + char\n",
    "\n",
    "print(no_punction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stop words and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NLP', 'important', 'deception', 'data', 'analytics', 'strong', 'skill', 'sets', 'NLP', 'great', 'chance', 'get', 'job', 'data', 'analytics', 'The', 'following', 'video', 'covers', 'important', 'topics', 'NLP', 'Please', 'watch', 'answer', 'following', 'questions', 'You', 'leave', 'comment', '2', 'peer', 'learners']\n"
     ]
    }
   ],
   "source": [
    "text_tokens = word_tokenize(no_punction)\n",
    "\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
    "\n",
    "print(tokens_without_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP  :  nlp\n",
      "important  :  import\n",
      "deception  :  decept\n",
      "data  :  data\n",
      "analytics  :  analyt\n",
      "strong  :  strong\n",
      "skill  :  skill\n",
      "sets  :  set\n",
      "NLP  :  nlp\n",
      "great  :  great\n",
      "chance  :  chanc\n",
      "get  :  get\n",
      "job  :  job\n",
      "data  :  data\n",
      "analytics  :  analyt\n",
      "The  :  the\n",
      "following  :  follow\n",
      "video  :  video\n",
      "covers  :  cover\n",
      "important  :  import\n",
      "topics  :  topic\n",
      "NLP  :  nlp\n",
      "Please  :  pleas\n",
      "watch  :  watch\n",
      "answer  :  answer\n",
      "following  :  follow\n",
      "questions  :  question\n",
      "You  :  you\n",
      "leave  :  leav\n",
      "comment  :  comment\n",
      "2  :  2\n",
      "peer  :  peer\n",
      "learners  :  learner\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer \n",
    "   \n",
    "ps = PorterStemmer() \n",
    "  \n",
    "for w in tokens_without_sw: \n",
    "    print(w, \" : \", ps.stem(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lemmitizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP - NLP\n",
      "important - important\n",
      "deception - deception\n",
      "data - data\n",
      "analytics - analytics\n",
      "strong - strong\n",
      "skill - skill\n",
      "sets - set\n",
      "NLP - NLP\n",
      "great - great\n",
      "chance - chance\n",
      "get - get\n",
      "job - job\n",
      "data - data\n",
      "analytics - analytics\n",
      "The - The\n",
      "following - following\n",
      "video - video\n",
      "covers - cover\n",
      "important - important\n",
      "topics - topic\n",
      "NLP - NLP\n",
      "Please - Please\n",
      "watch - watch\n",
      "answer - answer\n",
      "following - following\n",
      "questions - question\n",
      "You - You\n",
      "leave - leave\n",
      "comment - comment\n",
      "2 - 2\n",
      "peer - peer\n",
      "learners - learner\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for words in tokens_without_sw: \n",
    "    print(words + \" - \" + lemmatizer.lemmatize(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
